{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:/corporate_social_advocacy/round2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every folder, concatenate all the csv files under the same header, add the column for the query that was used to get it(filename), and then remove duplicate lines from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [ f.name for f in os.scandir(file_path) if f.is_dir() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion', 'climate_change', 'covid', 'gun_control', 'immigration', 'racism']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removal of duplicates 1269\n",
      "After removal of duplicates 1051\n",
      "completed  abortion\n",
      "Before removal of duplicates 1749\n",
      "After removal of duplicates 1478\n",
      "completed  climate_change\n",
      "Before removal of duplicates 402\n",
      "After removal of duplicates 374\n",
      "completed  covid\n",
      "Before removal of duplicates 1067\n",
      "After removal of duplicates 844\n",
      "completed  gun_control\n",
      "Before removal of duplicates 78\n",
      "After removal of duplicates 65\n",
      "completed  immigration\n",
      "Before removal of duplicates 6697\n",
      "After removal of duplicates 5878\n",
      "completed  racism\n"
     ]
    }
   ],
   "source": [
    "for folder in subfolders:\n",
    "    sub_file_path = file_path+folder+\"/\"\n",
    "    \n",
    "    os.chdir(sub_file_path)\n",
    "    all_files = glob.glob(os.path.join(sub_file_path, \"*.csv\"))\n",
    "  \n",
    "    all_df = []\n",
    "    for f in all_files:\n",
    "        df = pd.read_csv(f, sep=',')\n",
    "        query_file = f.split('\\\\')[-1]\n",
    "        df['file'] = query_file[:-4]\n",
    "        all_df.append(df)\n",
    "    merged_df = pd.concat(all_df, ignore_index=True, sort=True)\n",
    "    print(\"Before removal of duplicates\", len(merged_df))\n",
    "    merged_df = merged_df.drop_duplicates(subset='Embedded_text', keep=\"first\")\n",
    "    print(\"After removal of duplicates\", len(merged_df))\n",
    "    merged_df.to_csv(file_path+\"combined_\"+folder+\".csv\")\n",
    "    print(\"completed \",folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterDataCollection",
   "language": "python",
   "name": "twitterdatacollection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
